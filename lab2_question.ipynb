{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6027a45f-d731-4ff1-8527-b4db811bb2f9",
   "metadata": {
    "id": "fRuRcAt3F_wS"
   },
   "source": [
    "# INTRODUCTION TO DATA SCIENCE (MDA3003)**\n",
    "\n",
    "**Pengenalan Kepada Sains Data (MDA3003)**\n",
    "\n",
    "\n",
    ">R.U.Gobithaasan (2022). Fountation of Data Science, Lectures for Undergraduate Degree Program B.Sc (Data Analytics), Faculty of Ocean Engineering Technology, University Malaysia Terengganu.\n",
    "https://sites.google.com/site/gobithaasan/\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "     © 2022 R.U. Gobithaasan All Rights Reserved.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f645c31e-8483-437c-ba5f-5701b028b2b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Content of this course is adopted from the following books.\n",
    "  - [Introduction to Data Mining by Pang-ning Tan, Michael Steinbach, Vipin Kumar](https://www-users.cse.umn.edu/~kumar001/dmbook/index.php)\n",
    "  - [Data Mining and Machine Learning: Fundamental Concepts and Algorithms by\n",
    "Mohammed J. Zaki and Wagner Meira, Jr](https://dataminingbook.info/)\n",
    "\n",
    " - [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems by Aurélien Géron](https://github.com/ageron/handson-ml2)\n",
    "\n",
    "  - [Book: Data Science from Scratch First Principles with Python](https://www.oreilly.com/library/view/data-science-from/9781492041122/)\n",
    "  - [Github: Data Science from Scratch First Principles with Python](https://github.com/joelgrus/data-science-from-scratch)\n",
    "  - Jesus Rogel-Salazar, Data Science and Analytics with Python, CRC Press, Year: 2017\n",
    "  - Jesus Rogel-Salazar, Advanced Data Science and Analytics with Python, CRC Press, Year: 2020\n",
    "  - online ML work by [Jean de Dieu Nyandwi](https://nyandwi.com/machine_learning_complete/)\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556eeda8-eebe-4282-a398-416de61765b5",
   "metadata": {
    "id": "376ecc69-350c-48f7-90df-ca56bf958faf",
    "tags": []
   },
   "source": [
    "## Fill up the following declaration details:\n",
    "**I certify that this report is my own work, based on my personal study and/or research. I also certify that this report has not previously been submitted for assessment in any other unit, and that I have not copied in part or whole or otherwise plagiarised the work of other students and/or persons.**\n",
    "- Name:\n",
    "- Matrix Number: \n",
    "- Date: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f2554-7b84-4d4b-b909-30b9992fedaf",
   "metadata": {},
   "source": [
    "# MARKS\n",
    "\n",
    "| ATTRIBUTES    | MARKS |\n",
    "| ----------- | ----------- |\n",
    "| 1. MODULE/FUNCTION     |       |\n",
    "| 2. SYNTAX/CODE/ REASONING  |      |\n",
    "| 3. DOCUMENTATION    |       |\n",
    "\n",
    "\n",
    "**inaccurate code, didn't achieve final PCA reduction**\n",
    "\n",
    "<u>Marks For MODULE/FUNCTION:\n",
    "    \n",
    "Amateur (+1): Unable to use the right module/function.\n",
    "Acceptable (+2): Module /function is somewhat suitable.\n",
    "Admirable (+3): Module /function is suitable and partially solved the problem.\n",
    "Exceptional (+4): Module /function is are clearly identified and the problem is solved without errors.\n",
    "\n",
    "<u> Marks For SYNTAX/CODE/ REASONING :\n",
    "    \n",
    "Amateur (+1): Code is illogical, simplistic, inconsistent or does not work.\n",
    "Acceptable (+2): Code contains some elements of logic and/or creative insight.\n",
    "Admirable (+3): Code is mostly logical, complete, and consistent. Demonstrates some unique or creative insight.\n",
    "Exceptional (+4): Code is consistently creative, complete and often unique.\n",
    "\n",
    "<u> Marks For DOCUMENTATION:\n",
    "    \n",
    "Amateur (+1): Explanation is not stated or vague.\n",
    "Acceptable (+2): Able to explain with some justification.\n",
    "Admirable (+3): Conclusion mostly from results of analysis.\n",
    "Exceptional (+4): Full justification presented following clear concluding statement. Specifics and multiple perspectives are present.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd56f3-0608-4d91-b57c-e9080c8a6d49",
   "metadata": {
    "id": "45953749-32a4-4991-9a1d-636b06f9b0f5",
    "tags": []
   },
   "source": [
    "## General Instruction:\n",
    "Let say your matrix number is S54321. For computation below, ignore the first letter and use your matrix number by letting $\\mathbf{(\\alpha , \\beta, \\gamma, \\kappa, \\lambda) =(5,4,3,2,1)}$. Hence replace explicitly the values of greek letters as $\\alpha = 5, \\beta = 4, \\gamma = 3, \\kappa = 2, \\lambda =1$.\n",
    "\n",
    "\n",
    "For example:\n",
    "\n",
    "**Q0.** Compute $(\\beta * \\gamma * \\kappa)+{\\lambda})$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9069ae-3da6-41b9-88f1-cb26da15581c",
   "metadata": {},
   "source": [
    "# Lab 2: collection preparation, acquisition, cleaning and aggregation of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82e975-28ad-49ac-9960-82538ce11fd0",
   "metadata": {},
   "source": [
    "Lab 2 Content:\n",
    "\n",
    "**1. Data retrival:**\n",
    "- Using Pandas\n",
    "- Use Scikit-Learn data\n",
    "- Download data from internet \n",
    "- Use given data\n",
    "\n",
    "**2. Data Cleaning**\n",
    "- Missing value identification\n",
    "- Handling Missing Values\n",
    "- Data Saving: save your data as CSV\n",
    "\n",
    "\n",
    "**3. Data exploration**\n",
    "- Simple plot\n",
    "- Descriptive statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20279a7f-b826-4b31-8b5b-6c5a7628b5c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prelimineries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed003c35-1004-41e4-b463-2fc8a30ec5fb",
   "metadata": {
    "id": "716164b2-a3f2-45ce-910d-f3a1cfcff826"
   },
   "source": [
    "<b>Q1:Install the following and identify its version:</b>\n",
    "\n",
    "1. Pandas\n",
    "2. sklearn\n",
    "3. numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ff46a-11f2-4fb2-94df-742ec2142021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c7ff75-6753-41a6-b937-e62cee9d5aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.3\n",
      "1.0.2\n",
      "1.22.4\n"
     ]
    }
   ],
   "source": [
    "import sklearn, pandas, numpy\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b43d3-bd2f-4aff-9ded-1c9fb6337ddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Data Retrival (Cleaned) and Simple exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb398d-6ff5-43e9-831a-af57668c52bd",
   "metadata": {},
   "source": [
    "<b>Q2:Load Iris dataset from SK learn from its dataset module and do the following:</b>\n",
    "\n",
    "1. What is the type of the data? TIPS: They extend dictionaries by enabling values to be accessed by key, bunch[\"value_key\"], or by an attribute, bunch.value_key.\n",
    "\n",
    "2. Identify the keys in this dataset.\n",
    "3. Print its target, target names, desciption and feature names. Explain the code for each types of flower\n",
    "4. Print iris data and identify the type of iris data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3187cd3f-2173-475f-8bbe-3f132617013b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris() #Loading the dataset\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e79142-d8b0-4e42-8f0f-4d46b4161af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e414545b-0966-418c-a7fd-f06209454396",
   "metadata": {
    "id": "0PddFCfisTMo"
   },
   "source": [
    "A [DataFrame](https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html#) is a 2-dimensional data structure that can store data of different types (including characters, integers, floating point values, categorical data and more) in columns. It is similar to a spreadsheet, a SQL table or the data.frame in R.\n",
    "\n",
    "- Each column in a DataFrame is a **Series**. \n",
    "- If you are familiar to Python dictionaries, the selection of a single column is very similar to selection of dictionary values based on the key.\n",
    "- Let's store iris data inthe form of DataFrame\n",
    "- we use `info` to inspect the DataFrame representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa77359d-3ed8-406e-8260-793cf0e1ec3b",
   "metadata": {},
   "source": [
    "<b>Q3:Based on loaded Iris dataset, do the following:</b>\n",
    "\n",
    "1. Save the iris data in the form of Pandas Dataframe and name it as iris_data. Also, name the attributes based on the info obtained above. \n",
    "2. next add an extra column: the target name as its fifth attribute and print the data matrix\n",
    "3. identify the type of each attributes\n",
    "4. Use `head` and `tail` to inspect the first/last 5 rows\n",
    "5. Compute basic statistics of this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21b89cc9-cc57-4ba6-9dfe-f0da52f46ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris_data = pd.DataFrame(iris.data, columns = iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5528c47-1392-4369-8c57-b79e19777cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "006881a0-cacd-435d-9c24-6076c4974e40",
   "metadata": {
    "id": "R5RUapdSuLu-"
   },
   "source": [
    "<b>Q4:Based on loaded Iris dataset, do the following:</b>\n",
    "- Each column in a DataFrame is a **Series**. \n",
    "- If you are familiar to Python dictionaries, the selection of a single column is very similar to selection of dictionary values based on the key.\n",
    "\n",
    "1. Extract the sepal length from iris_data and save it as sepal_length. Check the type of this arrtibute.\n",
    "2. Compute mean and standard deviation of this attribute\n",
    "3. Visualize the frequency using histogram plot `matplotlib.pyplot` and state if its normal or non-normal distribution.\n",
    "4. Plot a line plot of the two features : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b862b6-2c80-4498-91b1-8f400526477d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a69e15eb-9a42-4bd5-b233-08451d35bd50",
   "metadata": {
    "id": "R5RUapdSuLu-"
   },
   "source": [
    "# Bonus\n",
    "<b>Q5:Load [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#examples-using-sklearn-datasets-fetch-california-housing \n",
    "), and do the following:\n",
    "-  Link of the details: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#examples-using-sklearn-datasets-fetch-california-housing \n",
    "\n",
    "1. Identify each type of attribute of California housing dataset.\n",
    "2.  Answer similar questions explored with Iris dataset (from question 1-3):</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d400e-e637-438c-888e-0cf819f63fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d34c51a4-9e07-45dd-8bfe-3ed295d5317b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Manual Data Loading (Uncleaned) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39783245-53be-412a-95a8-4179144fd85f",
   "metadata": {
    "id": "R5RUapdSuLu-"
   },
   "source": [
    "<b>Q5: Load and print given rainfall dataset from epembelajaran and do the following:\n",
    "  \n",
    "-  Rainfall station: Site 4232001 PEKAN AIR PUTIH at TERENGGANU\n",
    "    \n",
    "    1. view first two column.\n",
    "    2. view first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "776e6199-e967-4530-939b-ebef73785ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site 4731083 SEK. KEB. BKT. BESI at ULU DUNGUN</th>\n",
       "      <th>TERENGGANU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>Time</td>\n",
       "      <td>Rain mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29/06/1970</th>\n",
       "      <td>24:00:00</td>\n",
       "      <td>3.6?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/06/1970</th>\n",
       "      <td>24:00:00</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/07/1970</th>\n",
       "      <td>24:00:00</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/07/1970</th>\n",
       "      <td>24:00:00</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19/04/1973</th>\n",
       "      <td>24:00:00</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20/04/1973</th>\n",
       "      <td>24:00:00</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21/04/1973</th>\n",
       "      <td>24:00:00</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22/04/1973</th>\n",
       "      <td>24:00:00</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23/04/1973</th>\n",
       "      <td>24:00:00</td>\n",
       "      <td>0.3?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Site 4731083 SEK. KEB. BKT. BESI at ULU DUNGUN  TERENGGANU\n",
       "Date                                                 Time     Rain mm\n",
       "29/06/1970                                       24:00:00        3.6?\n",
       "30/06/1970                                       24:00:00         0.1\n",
       "01/07/1970                                       24:00:00         0.1\n",
       "02/07/1970                                       24:00:00         3.5\n",
       "...                                                   ...         ...\n",
       "19/04/1973                                       24:00:00         2.3\n",
       "20/04/1973                                       24:00:00         0.2\n",
       "21/04/1973                                       24:00:00        25.0\n",
       "22/04/1973                                       24:00:00         0.3\n",
       "23/04/1973                                       24:00:00        0.3?\n",
       "\n",
       "[1031 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\t\n",
    "#load dataframe from csv\n",
    "df = pd.read_csv(\"4731083.csv\")\n",
    "#print dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e5d28-f9fc-4a2c-8c9b-92b91f6d72c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8871b871-34e4-4b4f-8e03-a75f3c0935e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Data Cleaning/Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef9aa2-aa3f-4253-83cd-c49710727df6",
   "metadata": {
    "id": "R5RUapdSuLu-"
   },
   "source": [
    "<b>Q6: Do the following for Site 4731083 PEKAN AIR PUTIH at TERENGGANU\n",
    "    \n",
    "    1. extract the name of the rainfall from its first column and save it as station_name.\n",
    "    2. drop first column which represent time and the station name from DataFrame.\n",
    "    3. reset the row and column index of the dataframe and name it df_reset.\n",
    "    4. remove the unnecessary column names  and rename it as df_new.\n",
    "    5. reset the index as the date from column dataset.\n",
    "    6. Compute the number of days of rainfall data available.\n",
    "    7. Remove the \"?\" in the rainfall data and replace with NaN and rename this new dataframe as df_new\n",
    "    \n",
    "   </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d70de84-d5e9-4221-8283-c12f96925924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c220c31b-48c9-4941-af79-fd1a6425b3d8",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83bc810-61e7-4ae1-905b-de86e840494e",
   "metadata": {
    "id": "R5RUapdSuLu-"
   },
   "source": [
    "<b>Q7: Based on the cleanded dataset of Site 4731083 PEKAN AIR PUTIH at TERENGGANU, answer the following queston:\n",
    "    \n",
    "    1. Identify number of missing values (each '?' in rainfall indicates missing value)\n",
    "    2. Identify the missing value percentage of this site.\n",
    "    3. Remove all the dayd with missing values rename it as df_clean.\n",
    "    4. Plot the rainfall.\n",
    "    5. show its descriptive statistics (mean,median,mode,max,min etc.)\n",
    "\n",
    "    \n",
    "   </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1b212-bf8a-48dc-84f3-d2b3b96e0a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f441fd61-d74b-44b9-af9a-857e445e6d11",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3204ec3a-3ea0-4dee-83a4-190793210dad",
   "metadata": {},
   "source": [
    "<b>Q8:Load given rainfall dataset from Site 4232001  PEKAN AIR PUTIH at TERENGGANU and do the following:\n",
    "    \n",
    "1.  Clean the dataset annd plot the rainfall for this station.\n",
    "2. Show its descriptive statistics.\n",
    "\n",
    "    \n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294674f9-4213-4b6a-a40d-4f8adc95fa53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
